{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pressure Vessel: FEniCS + POD + Physics-Informed NN (Full Elasticity)\n",
        "\n",
        "This notebook demonstrates an end-to-end **open-source** pipeline:\n",
        "1) **Mesh generation** with Gmsh → 2) **FEniCS** simulations → 3) **POD** reduction →\n",
        "4) **PINN** surrogate with **full 3D elasticity residual** → 5) **Error analysis** → 6) **ParaView exports**.\n",
        "\n",
        "**Tip:** Run on a small mesh first (already set) to validate the pipeline, then refine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup: installs (optional) and imports\n",
        "Short description: install required libraries if you don't have them, then import everything we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# OPTIONAL installs (uncomment if needed)\n",
        "# %pip install gmsh meshio fenics torch matplotlib scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import gmsh\n",
        "import meshio\n",
        "from dolfin import *\n",
        "\n",
        "print('✅ Imports ready')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Mesh generation with Gmsh (small mesh for a quick demo)\n",
        "Short description: build a **hollow cylinder** (pressure vessel section) and tag the inner wall as a physical surface."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "gmsh.initialize()\n",
        "gmsh.model.add('small_vessel')\n",
        "\n",
        "# Geometry parameters (small for speed)\n",
        "R_outer = 0.5   # m\n",
        "L = 1.0         # m\n",
        "th = 0.05       # m (wall thickness)\n",
        "R_inner = R_outer - th\n",
        "lc = 0.15       # coarse element size\n",
        "\n",
        "# Outer and inner cylinders\n",
        "outer = gmsh.model.occ.addCylinder(0, 0, 0, 0, 0, L, R_outer)\n",
        "inner = gmsh.model.occ.addCylinder(0, 0, 0, 0, 0, L, R_inner)\n",
        "vessel, _ = gmsh.model.occ.cut([(3, outer)], [(3, inner)], removeObject=True, removeTool=True)\n",
        "gmsh.model.occ.synchronize()\n",
        "\n",
        "# Tag volume\n",
        "gmsh.model.addPhysicalGroup(3, [vessel[0][1]], tag=1)\n",
        "gmsh.model.setPhysicalName(3, 1, 'Vessel')\n",
        "\n",
        "# Tag inner wall (pressure boundary)\n",
        "inner_faces = gmsh.model.getBoundary([(3, vessel[0][1])], oriented=False)\n",
        "inner_surf_ids = [ent[1] for ent in inner_faces]\n",
        "gmsh.model.addPhysicalGroup(2, inner_surf_ids, tag=2)\n",
        "gmsh.model.setPhysicalName(2, 2, 'InnerWall')\n",
        "\n",
        "gmsh.option.setNumber('Mesh.CharacteristicLengthMin', lc)\n",
        "gmsh.option.setNumber('Mesh.CharacteristicLengthMax', lc)\n",
        "gmsh.model.mesh.generate(3)\n",
        "gmsh.write('vessel.msh')\n",
        "gmsh.finalize()\n",
        "print('✅ Gmsh mesh written to vessel.msh')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Convert mesh to XDMF for FEniCS\n",
        "Short description: use **meshio** to write separate XDMF files for volume and facet markers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "msh = meshio.read('vessel.msh')\n",
        "points = msh.points\n",
        "cells_tet = msh.get_cells_type('tetra')\n",
        "cells_tri = msh.get_cells_type('triangle')\n",
        "\n",
        "# Volume mesh with tetrahedra\n",
        "meshio.write('vessel_mesh.xdmf', meshio.Mesh(\n",
        "    points=points,\n",
        "    cells={'tetra': cells_tet},\n",
        "    cell_data={'name_to_read': [msh.cell_data_dict['gmsh:physical']['tetra']]}\n",
        "))\n",
        "\n",
        "# Facet markers for boundary conditions\n",
        "meshio.write('vessel_facets.xdmf', meshio.Mesh(\n",
        "    points=points,\n",
        "    cells={'triangle': cells_tri},\n",
        "    cell_data={'name_to_read': [msh.cell_data_dict['gmsh:physical']['triangle']]}\n",
        "))\n",
        "print('✅ XDMF written: vessel_mesh.xdmf, vessel_facets.xdmf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. FEniCS solver for linear elasticity with internal pressure\n",
        "Short description: assemble and solve the static elasticity problem with a **clamped end (z=0)** and **pressure on inner wall**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "mesh = Mesh()\n",
        "with XDMFFile('vessel_mesh.xdmf') as f:\n",
        "    f.read(mesh)\n",
        "\n",
        "mvc = MeshValueCollection('size_t', mesh, 2)\n",
        "with XDMFFile('vessel_facets.xdmf') as f:\n",
        "    f.read(mvc, 'name_to_read')\n",
        "facet_markers = cpp.mesh.MeshFunctionSizet(mesh, mvc)\n",
        "\n",
        "V = VectorFunctionSpace(mesh, 'Lagrange', 1)\n",
        "\n",
        "def solve_case(E_val, p_val, nu=0.3, inner_marker=2):\n",
        "    mu = E_val / (2*(1+nu))\n",
        "    lam = (E_val*nu) / ((1+nu)*(1-2*nu))\n",
        "    \n",
        "    def sigma(u):\n",
        "        return 2*mu*sym(grad(u)) + lam*tr(sym(grad(u)))*Identity(3)\n",
        "    \n",
        "    u = TrialFunction(V)\n",
        "    v = TestFunction(V)\n",
        "    a = inner(sigma(u), sym(grad(v)))*dx\n",
        "    \n",
        "    # Pressure as traction: -p * n on inner surface\n",
        "    n = FacetNormal(mesh)\n",
        "    ds = Measure('ds', domain=mesh, subdomain_data=facet_markers)\n",
        "    L = dot(-Constant(p_val)*n, v)*ds(inner_marker)\n",
        "    \n",
        "    # Clamp z=0 end\n",
        "    class Clamp(SubDomain):\n",
        "        def inside(self, x, on_boundary):\n",
        "            return on_boundary and near(x[2], 0.0, DOLFIN_EPS)\n",
        "    bc = DirichletBC(V, Constant((0,0,0)), Clamp())\n",
        "    \n",
        "    u_sol = Function(V)\n",
        "    solve(a == L, u_sol, bc)\n",
        "    return u_sol\n",
        "\n",
        "print('✅ FEniCS solver ready')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Parametric sweep & snapshot collection\n",
        "Short description: run a small grid over **E** and **p**, store flattened displacement vectors for POD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "E_vals = np.linspace(1.0e9, 5.0e9, 5)  # Pa (small range for demo)\n",
        "p_vals = np.linspace(1.0e5, 5.0e5, 5)  # Pa\n",
        "snapshots = []\n",
        "param_list = []\n",
        "\n",
        "for E in E_vals:\n",
        "    for p in p_vals:\n",
        "        u_sol = solve_case(E, p)\n",
        "        snapshots.append(u_sol.vector().get_local())\n",
        "        param_list.append([E, p])\n",
        "\n",
        "S = np.array(snapshots).T  # shape: (ndof, N)\n",
        "params = np.array(param_list)  # shape: (N, 2)\n",
        "print('Snapshot matrix shape:', S.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. POD basis (SVD) and coefficient extraction\n",
        "Short description: center snapshots, compute SVD, pick **r** modes, and get POD coefficients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_u = S.mean(axis=1, keepdims=True)\n",
        "X = S - mean_u\n",
        "U_svd, sing, VT = np.linalg.svd(X, full_matrices=False)\n",
        "energy = np.cumsum(sing**2) / np.sum(sing**2)\n",
        "r = min(10, np.searchsorted(energy, 0.999) + 1)  # keep up to 10 modes or 99.9% energy\n",
        "Phi = U_svd[:, :r]   # (ndof, r)\n",
        "A = Phi.T @ X        # (r, N) POD coefficients\n",
        "print(f'Chosen r={r}; Coeff matrix shape:', A.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Prepare training data (normalize inputs)\n",
        "Short description: split into train/test; normalize **(E,p)** for better NN conditioning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_in = params.astype(np.float64)\n",
        "y_out = A.T.astype(np.float64)\n",
        "\n",
        "X_mean = X_in.mean(axis=0)\n",
        "X_std = X_in.std(axis=0) + 1e-12\n",
        "Xn = (X_in - X_mean) / X_std\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xn, y_out, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test, dtype=torch.float32)\n",
        "print('Train set:', X_train_t.shape, y_train_t.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Define the PINN model (params → POD coefficients)\n",
        "Short description: small fully-connected NN with Tanh activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class POD_PINN(nn.Module):\n",
        "    def __init__(self, n_in=2, n_out=r, width=32):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_in, width), nn.Tanh(),\n",
        "            nn.Linear(width, width), nn.Tanh(),\n",
        "            nn.Linear(width, n_out)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = POD_PINN()\n",
        "loss_fn = nn.MSELoss()\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "print('✅ PINN model created')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Full 3D elasticity physics residual for PINN\n",
        "Short description: compute **div σ(u)** using autograd on a subset of mesh nodes. We reconstruct **u** via POD modes.\n",
        "\n",
        "**Note:** For production, build a DOF-to-node map from FEniCS to ensure component ordering matches `(ux, uy, uz)` per node."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "coords = mesh.coordinates()  # (Nnodes, 3)\n",
        "Nnodes = coords.shape[0]\n",
        "ndof = Phi.shape[0]\n",
        "assert ndof % 3 == 0, 'Expect 3 DOFs per node (vector field).'\n",
        "\n",
        "# Subsample for efficiency in the demo\n",
        "idx_sample = np.arange(0, Nnodes, max(1, Nnodes//800))  # ~<= 800 points\n",
        "coords_sample = coords[idx_sample]\n",
        "Np = coords_sample.shape[0]\n",
        "\n",
        "# Build a simple node-wise mode matrix (assumes DOF ordering [ux0, uy0, uz0, ux1, ...])\n",
        "def build_node_mode_matrix(Phi, node_indices):\n",
        "    # returns Phi_node of shape (Np*3, r) corresponding to selected nodes\n",
        "    rows = []\n",
        "    for n in node_indices:\n",
        "        rows.extend([3*n + 0, 3*n + 1, 3*n + 2])\n",
        "    return Phi[rows, :]\n",
        "\n",
        "Phi_node = build_node_mode_matrix(Phi, idx_sample)  # (Np*3, r)\n",
        "\n",
        "def physics_residual_loss_elasticity(model, Phi_node, coords_sample, X_batch_t, nu=0.3):\n",
        "    B = X_batch_t.shape[0]\n",
        "    coords_t = torch.tensor(coords_sample, dtype=torch.float32).repeat(B, 1, 1)  # [B, Np, 3]\n",
        "    coords_t.requires_grad_(True)\n",
        "    \n",
        "    # Predict POD coeffs\n",
        "    a_pred = model(X_batch_t)  # [B, r]\n",
        "    Phi_t = torch.tensor(Phi_node, dtype=torch.float32)  # [Np*3, r]\n",
        "    disp_flat = torch.einsum('br,nr->bn', a_pred, Phi_t)  # [B, Np*3]\n",
        "    disp = disp_flat.view(B, -1, 3)  # [B, Np, 3]\n",
        "    \n",
        "    # Material from (E,p) -> E only for residual; p handled via traction BC in data\n",
        "    # We use average E in the batch for mu, lam; for more fidelity, do per-sample loop\n",
        "    # Here we loop per sample to keep correctness.\n",
        "    phys_loss = 0.0\n",
        "    for b in range(B):\n",
        "        Xb = X_batch_t[b:b+1]\n",
        "        # de-normalize inputs\n",
        "        Xb_denorm = Xb.detach().cpu().numpy()*X_std + X_mean\n",
        "        E_val = float(Xb_denorm[0,0])\n",
        "        mu = E_val/(2*(1+nu))\n",
        "        lam = (E_val*nu)/((1+nu)*(1-2*nu))\n",
        "        \n",
        "        u = disp[b]  # [Np, 3]\n",
        "        grads = []\n",
        "        for i in range(3):\n",
        "            gi = torch.autograd.grad(u[:, i].sum(), coords_t[b], create_graph=True)[0]  # [Np, 3]\n",
        "            grads.append(gi)\n",
        "        grads = torch.stack(grads, dim=2)  # [Np, 3, 3]\n",
        "        eps = 0.5*(grads + grads.transpose(1, 2))          # [Np, 3, 3]\n",
        "        trace_eps = torch.einsum('nii->n', eps)             # [Np]\n",
        "        I = torch.eye(3)\n",
        "        sigma = lam*trace_eps[:,None,None]*I + 2*mu*eps     # [Np, 3, 3]\n",
        "        \n",
        "        # div sigma\n",
        "        div_sigma = []\n",
        "        for i in range(3):\n",
        "            div_i = 0\n",
        "            for j in range(3):\n",
        "                grad_sigma_ij = torch.autograd.grad(sigma[:, i, j].sum(), coords_t[b], create_graph=True)[0][:, j]\n",
        "                div_i = div_i + grad_sigma_ij\n",
        "            div_sigma.append(div_i)\n",
        "        div_sigma = torch.stack(div_sigma, dim=1)  # [Np, 3]\n",
        "        phys_loss = phys_loss + (div_sigma**2).mean()\n",
        "    \n",
        "    return phys_loss / B\n",
        "\n",
        "print('✅ Physics residual ready (full 3D elasticity).')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Train PINN with combined loss (data + physics)\n",
        "Short description: optimize the NN to fit POD coeffs **and** minimize PDE residual on sampled points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "alpha_data = 1.0\n",
        "beta_phys = 1e-3  # increase for stronger physics enforcement\n",
        "epochs = 400\n",
        "batch = X_train_t.shape[0]\n",
        "\n",
        "for ep in range(epochs):\n",
        "    opt.zero_grad()\n",
        "    pred = model(X_train_t)\n",
        "    loss_data = loss_fn(pred, y_train_t)\n",
        "    loss_phys = physics_residual_loss_elasticity(model, Phi_node, coords_sample, X_train_t)\n",
        "    loss = alpha_data*loss_data + beta_phys*loss_phys\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    if ep % 50 == 0:\n",
        "        print(f'Epoch {ep}: Data={loss_data.item():.3e}  Phys={loss_phys.item():.3e}  Total={loss.item():.3e}')\n",
        "print('✅ Training complete')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Predict on a new point and compare to FEniCS\n",
        "Short description: reconstruct displacement from predicted POD coeffs, compute **error**, and visualize distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Choose a test (E, p)\n",
        "E_test, p_test = 3.0e9, 3.5e5\n",
        "x_test = np.array([(E_test, p_test)], dtype=np.float64)\n",
        "x_test_n = (x_test - X_mean) / X_std\n",
        "x_test_t = torch.tensor(x_test_n, dtype=torch.float32)\n",
        "\n",
        "# Predict POD coeffs and reconstruct\n",
        "a_pred = model(x_test_t).detach().numpy().reshape(-1)\n",
        "u_pred = (Phi @ a_pred + mean_u.reshape(-1))  # (ndof,)\n",
        "\n",
        "# Ground truth from FEniCS\n",
        "u_true = solve_case(E_test, p_test).vector().get_local()\n",
        "\n",
        "# Error metrics\n",
        "abs_err = np.abs(u_true - u_pred)\n",
        "rel_err = np.linalg.norm(u_true - u_pred) / (np.linalg.norm(u_true) + 1e-14)\n",
        "print(f'Relative error: {rel_err:.3e}')\n",
        "\n",
        "# Histogram of absolute error\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(abs_err, bins=30)\n",
        "plt.xlabel('Absolute displacement error [m]')\n",
        "plt.ylabel('Count')\n",
        "plt.title('NN vs. FEniCS Displacement Error (per DOF)')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 3D scatter of error on nodes\n",
        "Short description: visualize where the surrogate deviates most (mini-ParaView in notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "coords_all = mesh.coordinates()\n",
        "err_node_mag = np.linalg.norm(abs_err.reshape(-1,3), axis=1)\n",
        "\n",
        "fig = plt.figure(figsize=(7,6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "pc = ax.scatter(coords_all[:,0], coords_all[:,1], coords_all[:,2], c=err_node_mag, s=10)\n",
        "ax.set_xlabel('X [m]'); ax.set_ylabel('Y [m]'); ax.set_zlabel('Z [m]')\n",
        "ax.set_title('Spatial Distribution of Displacement Error (|Δu|)')\n",
        "fig.colorbar(pc, ax=ax, label='|Δu| [m]')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Save XDMF fields for ParaView\n",
        "Short description: write **u_true**, **u_pred**, and scalar **error** to `.xdmf` for side-by-side comparison in ParaView."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def save_vector_field(filename, vec, mesh):\n",
        "    Vv = VectorFunctionSpace(mesh, 'CG', 1)\n",
        "    f = Function(Vv)\n",
        "    f.vector().set_local(vec)\n",
        "    with XDMFFile(filename) as xdmf:\n",
        "        xdmf.write(f)\n",
        "\n",
        "def save_scalar_field(filename, scal, mesh):\n",
        "    Vs = FunctionSpace(mesh, 'CG', 1)\n",
        "    f = Function(Vs)\n",
        "    f.vector().set_local(scal)\n",
        "    with XDMFFile(filename) as xdmf:\n",
        "        xdmf.write(f)\n",
        "\n",
        "# Save vector displacements\n",
        "save_vector_field('u_true.xdmf', u_true, mesh)\n",
        "save_vector_field('u_pred.xdmf', u_pred, mesh)\n",
        "\n",
        "# Save scalar error per DOF and per node magnitude\n",
        "save_scalar_field('error_per_dof.xdmf', abs_err, mesh)\n",
        "save_scalar_field('error_node_mag.xdmf', err_node_mag, mesh)\n",
        "print('✅ Saved: u_true.xdmf, u_pred.xdmf, error_per_dof.xdmf, error_node_mag.xdmf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes on libraries\n",
        "- **Gmsh** builds CAD geometry and generates high-quality tetrahedral meshes with boundary tags.\n",
        "- **meshio** converts between mesh formats (Gmsh `.msh` → FEniCS `.xdmf`).\n",
        "- **FEniCS (dolfin)** solves PDEs using finite elements. We model linear elasticity and export fields to XDMF.\n",
        "- **POD** (SVD) reduces dimensionality by extracting dominant modes from snapshots.\n",
        "- **PINN (Physics-Informed NN)** augments data loss with **PDE residual loss** to enforce physics and improve generalization.\n",
        "\n",
        "For production, consider: higher mesh resolution, robust DOF-node mapping, stress-based losses, multi-materials, and more advanced NN architectures."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "authors": [
      {
        "name": "ChatGPT"
      }
    ],
    "created": "2025-08-14T00:43:56.819614Z"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}